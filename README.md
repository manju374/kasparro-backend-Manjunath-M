# üöÄ Kasparro Backend - Crypto Analytics Platform

A high-performance backend system for ingesting, normalizing, and serving cryptocurrency market data. This project demonstrates a robust **ETL Pipeline** and **RESTful API** architecture.

---

## üìÇ Project Structure

```text
kasparro-backend/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ main.py              # Entry point
‚îÇ   ‚îú‚îÄ‚îÄ models.py            # Database Tables
‚îÇ   ‚îú‚îÄ‚îÄ schemas.py           # API Response Models
‚îÇ   ‚îú‚îÄ‚îÄ init_db.py           # DB Initialization Script
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ routes.py        # API Endpoints
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py        # Settings
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ database.py      # DB Connection
‚îÇ   ‚îú‚îÄ‚îÄ ingestion/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pipeline.py      # Main ETL Script
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ csv_loader.py    # CSV Parser
‚îÇ   ‚îî‚îÄ‚îÄ services/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ coinpaprika.py   # API Adapter 1
‚îÇ       ‚îî‚îÄ‚îÄ coingecko.py     # API Adapter 2
‚îú‚îÄ‚îÄ .env                     # Secrets (NOT in GitHub)
‚îú‚îÄ‚îÄ .gitignore               # git config
‚îú‚îÄ‚îÄ docker-compose.yml       # Infrastructure
‚îú‚îÄ‚îÄ Dockerfile               # Build instructions
‚îú‚îÄ‚îÄ historical_data.csv      # Dummy Data
‚îú‚îÄ‚îÄ run.sh                   # Startup Script
‚îú‚îÄ‚îÄ README.md                # Documentation
‚îî‚îÄ‚îÄ requirements.txt         # Dependencies
```

## üèó Architecture

The system follows a **Service-Oriented Architecture (SOA)** with a focus on data integrity and modularity.

```mermaid
graph LR
    A[Data Sources] -->|Fetch JSON| B(Ingestion Service)
    B -->|Normalize| C{PostgreSQL Database}
    D[CSV Upload] -->|Parse| C
    C -->|Query| E[FastAPI Backend]
    E -->|Serve JSON| F[Client / Frontend]
```

### Key Components:
1.  **Ingestion Engine:** Fetches data from multiple sources (CoinPaprika, CoinGecko) and normalizes it into a unified schema.
2.  **Raw Data Storage:** Implements an "Audit Trail" by storing raw JSON payloads before processing.
3.  **API Layer:** Fast, paginated endpoints served via **FastAPI** and **Uvicorn**.
4.  **Containerization:** Fully Dockerized environment for consistent deployment.

---

## üõ† Tech Stack
-   **Language:** Python 3.9
-   **Framework:** FastAPI
-   **Database:** PostgreSQL 15
-   **ORM:** SQLAlchemy
-   **Infrastructure:** Docker & Docker Compose

---

## ‚ö°Ô∏è Quick Start (Local)

### Prerequisites
-   Docker & Docker Compose installed.

### 1. Clone the Repository
```bash
git clone <YOUR_REPO_URL>
cd kasparro-backend
```

### 2. Configure Environment
Create a `.env` file in the root directory:
```env
DATABASE_URL=postgresql://postgres:postgres@db:5432/kasparro
COINPAPRIKA_API_KEY=your_key_here
COINGECKO_API_KEY=your_key_here
```

### 3. Run with Docker
```bash
docker-compose up --build -d
```

### 4. Initialize Database & Data
```bash
# Create Tables
docker-compose exec backend python -m app.init_db

# Run ETL Pipeline (CoinPaprika + CoinGecko)
docker-compose run --rm backend python -m app.ingestion.pipeline

# Load Historical CSV Data
docker-compose exec backend python -m app.ingestion.csv_loader
```

---

## üì° API Endpoints

| Method | Endpoint | Description |
| :--- | :--- | :--- |
| `GET` | `/health` | Check DB connection and system status. |
| `GET` | `/data` | Retrieve market data (Supports pagination `limit` & `offset`). |

**Example Request:**
```bash
curl "http://localhost:8000/data?limit=5&symbol=BTC"
```

---

## ‚úÖ Completed Requirements

- [x] **Tier P0: Foundation**
    - [x] Dockerized Environment
    - [x] PostgreSQL Database with SQLAlchemy Models
    - [x] Data Ingestion (CoinPaprika API + CSV)
- [x] **Tier P1: Reliability**
    - [x] Multi-source support (Added CoinGecko)
    - [x] Data Normalization
    - [x] Raw Data Auditing
